<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Tuan Ngo  Nguyen</title>
<meta name="description" content="Tuan Nguyen's Personal Page.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXXX');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    
<header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <!--  -->
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="navbar-collapse collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
		  <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
              <span class="sr-only">(current)</span>
              
            </a>
          </li>
		  <!-- Publications -->
		  <li class="nav-item  ">
            <a class="nav-link" href="/publications/">
              Publications
              
            </a>
          </li>
          <!-- <\!-- Blog -\-> -->
		  <!-- <li class="nav-item  "> -->
          <!--   <a class="nav-link" href="/blog/"> -->
          <!--     Blog -->
          <!--      -->
          <!--   </a> -->
          <!-- </li> -->
		  <li class="nav-item  ">
			<a class="nav-link" href="/assets/pdf/tnguyen_cv.pdf">CV
			  
			</a>
          </li>
		  
          
          <div class = "toggle-container">
            <a id = "light-toggle">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </a>
          </div>
          
        </ul>
      </div>
    </div>
  </nav>
</header>


    <!-- Content -->
    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h2 class="post-title">
     <!-- <span class="font-weight-bold">Tuan Ngo</span>  Nguyen -->
     Tuan Ngo Nguyen
    </h2>
	<p class="post-description"></p>
  </header>

  <article>
	<div class="row">
	  <div class="col-sm-8 pl-4">
		<p>Hi! I am a 3rd year Ph.D. student in Computer Science at the UA. I am fortunate to be advised by Prof. <a href="https://kwangsungjun.github.io/">Kwang-Sung Jun</a>, working on decision-making algorithms. I obtained my M.S. degree in Computer Science from the UO, working with Prof. <a href="https://ix.cs.uoregon.edu/~thien/">Thien Huu Nguyen</a> in domain adaptation and multi-lingual Natural Language Processing (NLP). 
<!-- . I received my Bachelor's degree in Finance from [CUNY Baruch College](https://www.baruch.cuny.edu). --></p>

<p>My research interests lie in adaptive decision-making algorithms, including bandit algorithms, Monte Carlo Tree Search, and Reinforcement Learning. In particular, my work focuses on developing algorithms that provably adapt to the difficulty and complexity of particular problem instances, and perform optimally in worst-case and/or adversarial scenarios.</p>

<!-- I am broadly interested in theoretical computer science and machine learning. In particular, I am interested in developing and analyzing adaptive decision-making algorithms including bandit algorithms, Monte Carlo tree search methods, and reinforcement learning. -->

<!-- My broad research interests lie in learning machine learning algorithms and innovating solutions for vision and languages problems. I am particularly interested in unsupervised domain adaptation and semi-supervised learning. My research has been focusing on applying unsupervised domain adaptation algorithms for cross-lingual and multi-lingual NLP problems. -->

<!-- I have strong desire to do research, learning and creating new potentially useful theories and applications. I am currently looking for a PhD position that focuses machine learning projects. -->


	  </div>
	  <div class="col-sm-4">
		<img class="img-fluid z-depth-1 rounded" src="/assets/img/profile_pic_v11.jpg" alt="Tuan Profile Pic">
		<div class="row">
		  <ul class="social-icons">
			<li><a class="mailto" href="mailto:%74%6E%67%75%79%65%6E%39%32%31%30@%67%6D%61%69%6C.%63%6F%6D" title="Mail">Mail</a></li>
			<li><a class="scholar" href="https://scholar.google.com/citations?user=QaXb3b4AAAAJ&hl=en" title="Google Scholar">Google Scholar</a></li>
			<li><a class="github" href="https://github.com/tnguyen9210" title="Github">Github</a></li>
			<li><a class="linkedin" href="https://www.linkedin.com/in/tnguyen9210" title="Linkedin">LinkedIn</a></li>
			<li><a class="zotero" href="https://www.zotero.org/tnguyen9210/library" title="Zotero">Zotero</a></li>
		  </ul>
		</div>
		<div class="row">
		  <ul class="social-icons">
			<li><a class="c_lang" href="https://en.cppreference.com/w/c/language" title="C">C</a></li>
			<li><a class="python" href="https://www.python.org/" title="Python">Python</a></li>
			<li><a class="emacs" href="https://www.gnu.org/software/emacs/" title="Emacs">Emacs</a></li>
			<li><a class="archlinux" href="https://archlinux.org/" title="ArchLinux">ArchLinux</a></li>
		  </ul>
		</div>
	  </div>
	</div>
    
    <!--  -->

    <div class="publications" >
	  <h2>Selected Publications</h2>
	  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="nguyen2024Haver">
    
      <span class="title">HAVER: Instance-Dependent Error Bounds for Maximum Mean Estimation and Applications to Q-Learning</span>.
      <div class="author">
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>
              
            
          
        
          
          

		  
            
              
                and Kwang-Sung Jun.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In arxiv</em>.
      
      <!--  -->
      <!--   2024 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a class="to_appear">To Appear</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We study the problem of estimating the <i>value</i> of the largest mean among distributions via samples from them (rather than estimating <i>which</i> distribution has the largest mean), which arises from various machine learning tasks including Q-learning and Monte Carlo tree search. While there have been a few proposed algorithms, their performance analyses have been limited to their biases rather than a precise error metric. In this paper, we propose a novel algorithm called HAVER (Head AVERaging) and analyze its mean squared error. Our analysis reveals that HAVER has a compelling performance in two respects. First, HAVER estimates the maximum mean as well as the oracle who knows the identity of the best distribution and reports its sample mean. Second, perhaps surprisingly, HAVER exhibits even better rates than this oracle when there are many distributions near the best one. Both of these improvements are the first of their kind in the literature, and we also prove that the naive algorithm that reports the largest empirical mean does not achieve these bounds. Finally, we confirm our theoretical findings via numerical experiments including bandits and Q-learning scenarios where HAVER outperforms baseline methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="nguyen2024Fixing">
    
      <span class="title">Fixing the Loose Brake: Exponential Tail Bounds for Stopping Time in Best Arm Identification</span>.
      <div class="author">
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
              Kapilan Balagopalan,
              
            
          
        
          
          

		  
            
              
              Yao Zhao,
              
            
          
        
          
          

		  
            
              
                and Kwang-Sung Jun.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In arxiv</em>.
      
      <!--  -->
      <!--   2024 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a class="to_appear">To Appear</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The best arm identification problem requires identifying the best alternative (i.e., arm) in active experimentation using the smallest number of experiments (i.e., arm pulls), which is crucial for cost-efficient and timely decision-making processes. In the fixed confidence setting, an algorithm must stop data-dependently and return the estimated best arm with a correctness guarantee. Since this stopping time is random, we desire its distribution to have light tails. Unfortunately, many existing studies focus on high probability or in expectation bounds on the stopping time, which allow heavy tails and, for high probability bounds, even not stopping at all. We first prove that this never-stopping event can indeed happen for some popular algorithms. Motivated by this, we propose algorithms that provably enjoy an exponential-tailed stopping time, which improves upon the polynomial tail bound reported by Kalyanakrishnan et al. (2012). The first algorithm is based on a fixed budget algorithm called Sequential Halving along with a doubling trick. The second algorithm is a meta algorithm that takes in any fixed confidence algorithm with a high probability stopping guarantee and turns it into one that enjoys an exponential-tailed stopping time. Our results imply that there is much more to be desired for contemporary fixed confidence algorithms.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="nguyen2021Crosslingual">
    
      <span class="title">Crosslingual Transfer Learning for Relation and Event Extraction via Word Category and Class Alignments</span>.
      <div class="author">
        
          
          

		  
            
              
              Minh Van Nguyen,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
              Bonan Min,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the EMNLP 2021</em>.
      
      <!--  -->
      <!--   2021 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://aclanthology.org/2021.emnlp-main.440" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Previous work on crosslingual Relation and Event Extraction (REE) suffers from the monolingual bias issue due to the training of models on only the source language data. An approach to overcome this issue is to use unlabeled data in the target language to aid the alignment of crosslingual representations, i.e., via fooling a language discriminator. However, as this approach does not condition on class information, a target language example of a class could be incorrectly aligned to a source language example of a different class. To address this issue, we propose a novel crosslingual alignment method that leverages class information of REE tasks for representation learning. In particular, we propose to learn two versions of representation vectors for each class in an REE task based on either source or target language examples. Representation vectors for corresponding classes will then be aligned to achieve class-aware alignment for crosslingual representations. In addition, we propose to further align representation vectors for language universal word categories (i.e., parts of speech and dependency relations). As such, a novel filtering mechanism is presented to facilitate the learning of word category representations from contextualized representations on input texts based on adversarial learning. We conduct extensive crosslingual experiments with English, Chinese, and Arabic over REE tasks. The results demonstrate the benefits of the proposed method that significantly advances the state-of-the-art performance in these settings.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="lai2020event">
    
      <span class="title">Event Detection: Gate Diversity and Syntactic Importance Scoresfor Graph Convolution Neural Networks</span>.
      <div class="author">
        
          
          

		  
            
              
              Viet Dac Lai,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the EMNLP 2020</em>.
      
      <!--  -->
      <!--   2020 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://arxiv.org/abs/2010.14123" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent studies on event detection (ED) haveshown that the syntactic dependency graph canbe employed in graph convolution neural net-works (GCN) to achieve state-of-the-art per-formance. However, the computation of thehidden vectors in such graph-based models isagnostic to the trigger candidate words, po-tentially leaving irrelevant information for thetrigger candidate for event prediction. In addi-tion, the current models for ED fail to exploitthe overall contextual importance scores of thewords, which can be obtained via the depen-dency tree, to boost the performance. In thisstudy, we propose a novel gating mechanismto filter noisy information in the hidden vec-tors of the GCN models for ED based on theinformation from the trigger candidate. Wealso introduce novel mechanisms to achievethe contextual diversity for the gates and theimportance score consistency for the graphsand models in ED. The experiments show thatthe proposed model achieves state-of-the-artperformance on two ED datasets.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="veyseh2020graph">
    
      <span class="title">Graph Transformer Networks with Syntactic and Semantic Structures for Event Argument Extraction</span>.
      <div class="author">
        
          
          

		  
            
              
              Amir Pouran Ben Veyseh,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Findings of the EMNLP 2020</em>.
      
      <!--  -->
      <!--   2020 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://arxiv.org/abs/2010.13391" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The goal of Event Argument Extraction (EAE) is to find the role of each entity mention for a given event trigger word. It has been shown in the previous works that the syntactic structures of the sentences are helpful for the deep learning models for EAE. However, a major problem in such prior works is that they fail to exploit the semantic structures of the sentences to induce effective representations for EAE. Consequently, in this work, we propose a novel model for EAE that exploits both syntactic and semantic structures of the sentences with the Graph Transformer Networks (GTNs) to learn more effective sentence structures for EAE. In addition, we introduce a novel inductive bias based on information bottleneck to improve generalization of the EAE models. Extensive experiments are performed to demonstrate the benefits of the proposed model, leading to state-of-the-art performance for EAE on standard datasets.</p>
    </div>
    
  </div>
</div>
</li></ol>
	</div>
  </article>

</div>

    </div>

    <!-- Footer -->
    

<footer>
  <div class="container mt-5">
    &copy; Copyright 2024 Tuan Ngo  Nguyen.<br>
	Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
