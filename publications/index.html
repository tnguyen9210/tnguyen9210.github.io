<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Tuan Ngo  Nguyen | Publications</title>
<meta name="description" content="Tuan Nguyen's Personal Page.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXXX');
  </script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    
<header>
  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <!--  -->
      <!-- <a class="navbar-brand title font-weight-lighter" href="/"> -->
		<!-- 	Tuan Ngo Nguyen -->
		<!-- </a> -->
      <!--  -->
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="navbar-collapse collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
		  <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
		  <!-- Publications -->
		  <li class="nav-item active ">
            <a class="nav-link" href="/publications/">
              Publications
              
              <span class="sr-only">(current)</span>
              
            </a>
          </li>
          <!-- <\!-- Blog -\-> -->
		  <!-- <li class="nav-item  "> -->
          <!--   <a class="nav-link" href="/blog/"> -->
          <!--     Blog -->
          <!--      -->
          <!--   </a> -->
          <!-- </li> -->
		  <li class="nav-item  ">
			<a class="nav-link" href="/assets/pdf/tnguyen_cv.pdf">CV
			  
			</a>
          </li>
		  
          
          <div class = "toggle-container">
            <a id = "light-toggle">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </a>
          </div>
          
        </ul>
      </div>
    </div>
  </nav>
</header>


    <!-- Content -->
    <div class="container mt-5">
      <div class="post">
  
  <header class="post-header">
    <h2 class="post-title">Publications</h2>
    <p class="post-description">Publications by years in reversed chronological order.<br>
Generated by jekyll-scholar.
</p>
  </header>

  <article>
    <div class="publications">


  <h3 class="year">2024</h3>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="nguyen2024Haver">
    
      <span class="title">HAVER: Instance-Dependent Error Bounds for Maximum Mean Estimation and Applications to Q-Learning</span>.
      <div class="author">
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>
              
            
          
        
          
          

		  
            
              
                and Kwang-Sung Jun.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In arxiv</em>.
      
      <!--  -->
      <!--   2024 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a class="to_appear">To Appear</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We study the problem of estimating the <i>value</i> of the largest mean among distributions via samples from them (rather than estimating <i>which</i> distribution has the largest mean), which arises from various machine learning tasks including Q-learning and Monte Carlo tree search. While there have been a few proposed algorithms, their performance analyses have been limited to their biases rather than a precise error metric. In this paper, we propose a novel algorithm called HAVER (Head AVERaging) and analyze its mean squared error. Our analysis reveals that HAVER has a compelling performance in two respects. First, HAVER estimates the maximum mean as well as the oracle who knows the identity of the best distribution and reports its sample mean. Second, perhaps surprisingly, HAVER exhibits even better rates than this oracle when there are many distributions near the best one. Both of these improvements are the first of their kind in the literature, and we also prove that the naive algorithm that reports the largest empirical mean does not achieve these bounds. Finally, we confirm our theoretical findings via numerical experiments including bandits and Q-learning scenarios where HAVER outperforms baseline methods.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="nguyen2024Fixing">
    
      <span class="title">Fixing the Loose Brake: Exponential Tail Bounds for Stopping Time in Best Arm Identification</span>.
      <div class="author">
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
              Kapilan Balagopalan,
              
            
          
        
          
          

		  
            
              
              Yao Zhao,
              
            
          
        
          
          

		  
            
              
                and Kwang-Sung Jun.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In arxiv</em>.
      
      <!--  -->
      <!--   2024 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a class="to_appear">To Appear</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The best arm identification problem requires identifying the best alternative (i.e., arm) in active experimentation using the smallest number of experiments (i.e., arm pulls), which is crucial for cost-efficient and timely decision-making processes. In the fixed confidence setting, an algorithm must stop data-dependently and return the estimated best arm with a correctness guarantee. Since this stopping time is random, we desire its distribution to have light tails. Unfortunately, many existing studies focus on high probability or in expectation bounds on the stopping time, which allow heavy tails and, for high probability bounds, even not stopping at all. We first prove that this never-stopping event can indeed happen for some popular algorithms. Motivated by this, we propose algorithms that provably enjoy an exponential-tailed stopping time, which improves upon the polynomial tail bound reported by Kalyanakrishnan et al. (2012). The first algorithm is based on a fixed budget algorithm called Sequential Halving along with a doubling trick. The second algorithm is a meta algorithm that takes in any fixed confidence algorithm with a high probability stopping guarantee and turns it into one that enjoys an exponential-tailed stopping time. Our results imply that there is much more to be desired for contemporary fixed confidence algorithms.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h3 class="year">2021</h3>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="nguyen2021Crosslingual">
    
      <span class="title">Crosslingual Transfer Learning for Relation and Event Extraction via Word Category and Class Alignments</span>.
      <div class="author">
        
          
          

		  
            
              
              Minh Van Nguyen,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
              Bonan Min,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the EMNLP 2021</em>.
      
      <!--  -->
      <!--   2021 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://aclanthology.org/2021.emnlp-main.440" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Previous work on crosslingual Relation and Event Extraction (REE) suffers from the monolingual bias issue due to the training of models on only the source language data. An approach to overcome this issue is to use unlabeled data in the target language to aid the alignment of crosslingual representations, i.e., via fooling a language discriminator. However, as this approach does not condition on class information, a target language example of a class could be incorrectly aligned to a source language example of a different class. To address this issue, we propose a novel crosslingual alignment method that leverages class information of REE tasks for representation learning. In particular, we propose to learn two versions of representation vectors for each class in an REE task based on either source or target language examples. Representation vectors for corresponding classes will then be aligned to achieve class-aware alignment for crosslingual representations. In addition, we propose to further align representation vectors for language universal word categories (i.e., parts of speech and dependency relations). As such, a novel filtering mechanism is presented to facilitate the learning of word category representations from contextualized representations on input texts based on adversarial learning. We conduct extensive crosslingual experiments with English, Chinese, and Arabic over REE tasks. The results demonstrate the benefits of the proposed method that significantly advances the state-of-the-art performance in these settings.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="phung2021Hierarchical">
    
      <span class="title">Hierarchical Graph Convolutional Networks for Jointly Resolving Cross-Document Coreference of Entity and Event Mentions</span>.
      <div class="author">
        
          
          

		  
            
              
              Duy Phung,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the NAACL-HLT TextGraphs Workshop 2021</em>.
      
      <!--  -->
      <!--   2021 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://aclanthology.org/2021.textgraphs-1.4" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper studies the problem of cross-document event coreference resolution (CDECR) that seeks to determine if event mentions across multiple documents refer to the same real-world events. Prior work has demonstrated the benefits of the predicate-argument information and document context for resolving the coreference of event mentions. However, such information has not been captured effectively in prior work for CDECR. To address these limitations, we propose a novel deep learning model for CDECR that introduces hierarchical graph convolutional neural networks (GCN) to jointly resolve entity and event mentions. As such, sentence-level GCNs enable the encoding of important context words for event mentions and their arguments while the document-level GCN leverages the interaction structures of event mentions and arguments to compute document representations to perform CDECR. Extensive experiments are conducted to demonstrate the effectiveness of the proposed model.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h3 class="year">2020</h3>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="lai2020event">
    
      <span class="title">Event Detection: Gate Diversity and Syntactic Importance Scoresfor Graph Convolution Neural Networks</span>.
      <div class="author">
        
          
          

		  
            
              
              Viet Dac Lai,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the EMNLP 2020</em>.
      
      <!--  -->
      <!--   2020 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://arxiv.org/abs/2010.14123" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent studies on event detection (ED) haveshown that the syntactic dependency graph canbe employed in graph convolution neural net-works (GCN) to achieve state-of-the-art per-formance. However, the computation of thehidden vectors in such graph-based models isagnostic to the trigger candidate words, po-tentially leaving irrelevant information for thetrigger candidate for event prediction. In addi-tion, the current models for ED fail to exploitthe overall contextual importance scores of thewords, which can be obtained via the depen-dency tree, to boost the performance. In thisstudy, we propose a novel gating mechanismto filter noisy information in the hidden vec-tors of the GCN models for ED based on theinformation from the trigger candidate. Wealso introduce novel mechanisms to achievethe contextual diversity for the gates and theimportance score consistency for the graphsand models in ED. The experiments show thatthe proposed model achieves state-of-the-artperformance on two ED datasets.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="veyseh2020graph">
    
      <span class="title">Graph Transformer Networks with Syntactic and Semantic Structures for Event Argument Extraction</span>.
      <div class="author">
        
          
          

		  
            
              
              Amir Pouran Ben Veyseh,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Findings of the EMNLP 2020</em>.
      
      <!--  -->
      <!--   2020 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://arxiv.org/abs/2010.13391" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The goal of Event Argument Extraction (EAE) is to find the role of each entity mention for a given event trigger word. It has been shown in the previous works that the syntactic structures of the sentences are helpful for the deep learning models for EAE. However, a major problem in such prior works is that they fail to exploit the semantic structures of the sentences to induce effective representations for EAE. Consequently, in this work, we propose a novel model for EAE that exploits both syntactic and semantic structures of the sentences with the Graph Transformer Networks (GTNs) to learn more effective sentence structures for EAE. In addition, we introduce a novel inductive bias based on information bottleneck to improve generalization of the EAE models. Extensive experiments are performed to demonstrate the benefits of the proposed model, leading to state-of-the-art performance for EAE on standard datasets.</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="ngo2020learning">
    
      <span class="title">Learning to Select Important Context Words for Event Detection</span>.
      <div class="author">
        
          
          

		  
            
              
              Nghia Trung Ngo,
              
            
          
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the PAKDD 2020</em>.
      
      <!--  -->
      <!--   2020 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://link.springer.com/chapter/10.1007/978-3-030-47436-2_57" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>It is important to locate important context words in the sentences and model them appropriately to perform event detection (ED) effectively. This has been mainly achieved by some fixed word selection strategy in the previous studies for ED. In this work, we propose a novel method that learns to select relevant context words for ED based on the Gumbel-Softmax trick. The extensive experiments demonstrate the effectiveness of the proposed method, leading to the state-of-the-art performance for ED over different benchmark datasets and settings.</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h3 class="year">2019</h3>
  <ol class="bibliography"><li><div class="row">
  <!-- <div class="col-sm-2 abbr"> -->
  <!--  -->
  <!-- </div> -->

  <div id="nguyen2019effectiveness">
    
      <span class="title">On the Effectiveness of the Pooling Methods for Biomedical Relation Extraction with Deep Learning</span>.
      <div class="author">
        
          
          

		  
            
              
              <em>Tuan Ngo Nguyen</em>,
              
            
          
        
          
          

		  
            
              
              Franck Dernoncourt,
              
            
          
        
          
          

		  
            
              
                and Thien Huu Nguyen.
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the EMNLP LOUHI Workshop 2019</em>.
      
      <!--  -->
      <!--   2019 -->
      <!--  -->
      </div>
    

    <div class="links">
    
      <!-- <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> -->
      [<a class="abstract">Abstract</a>]
    
    
      [<a href="https://arxiv.org/abs/1911.01055" target="_blank">Paper</a>]
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Deep learning models have achieved state-of-the-art performances on many relation extraction datasets. A common element in these deep learning models involves the pooling mechanisms where a sequence of hidden vectors is aggregated to generate a single representation vector, serving as the features to perform prediction for RE. Unfortunately, the models in the literature tend to employ different strategies to perform pooling for RE, leading to the challenge to determine the best pooling mechanism for this problem, especially in the biomedical domain. In order to answer this question, in this work, we conduct a comprehensive study to evaluate the effectiveness of different pooling mechanisms for the deep learning models in biomedical RE. The experimental results suggest that dependency-based pooling is the best pooling strategy for RE in the biomedical domain, yielding the state-of-the-art performance on two benchmark datasets for this problem.</p>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </article>
  
</div>

    </div>

    <!-- Footer -->
    

<footer>
  <div class="container mt-5">
    &copy; Copyright 2024 Tuan Ngo  Nguyen.<br>
	Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
